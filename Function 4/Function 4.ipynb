{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03012f8b",
   "metadata": {},
   "source": [
    "# Function 4 - Warehouse Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03de60",
   "metadata": {},
   "source": [
    "### First Inspection\n",
    "\n",
    "According to the description: Address the challenge of optimally placing products across warehouses for a business with high online sales, where accurate calculations are costly and only feasible biweekly. To speed up decision-making, an ML model $f(\\mathbf{x})$ approximates these results within hours. The model has four hyperparameters, $x_1, x_2. x_3$ and $x_4$ to tune, and its output $y$ reflects the difference from the expensive baseline. Because the system is dynamic and full of local optima, it requires careful tuning and robust validation to find reliable, near-optimal solutions. \n",
    "\n",
    "Let us load and inspect the evalutations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06de5c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89698105, 0.72562797, 0.17540431, 0.70169437],\n",
       "       [0.8893564 , 0.49958786, 0.53926886, 0.50878344],\n",
       "       [0.25094624, 0.03369313, 0.14538002, 0.49493242],\n",
       "       [0.34696206, 0.0062504 , 0.76056361, 0.61302356],\n",
       "       [0.12487118, 0.12977019, 0.38440048, 0.2870761 ],\n",
       "       [0.80130271, 0.50023109, 0.70664456, 0.19510284],\n",
       "       [0.24770826, 0.06044543, 0.04218635, 0.44132425],\n",
       "       [0.74670224, 0.7570915 , 0.36935306, 0.20656628],\n",
       "       [0.40066503, 0.07257425, 0.88676825, 0.24384229],\n",
       "       [0.6260706 , 0.58675126, 0.43880578, 0.77885769],\n",
       "       [0.95713529, 0.59764438, 0.76611385, 0.77620991],\n",
       "       [0.73281243, 0.14524998, 0.47681272, 0.13336573],\n",
       "       [0.65511548, 0.07239183, 0.68715175, 0.08151656],\n",
       "       [0.21973443, 0.83203134, 0.48286416, 0.08256923],\n",
       "       [0.48859419, 0.2119651 , 0.93917791, 0.37619173],\n",
       "       [0.16713049, 0.87655456, 0.21723954, 0.95980098],\n",
       "       [0.21691119, 0.16608583, 0.24137226, 0.77006248],\n",
       "       [0.38748784, 0.80453226, 0.75179548, 0.72382744],\n",
       "       [0.98562189, 0.66693268, 0.15678328, 0.8565348 ],\n",
       "       [0.03782483, 0.66485335, 0.16198218, 0.25392378],\n",
       "       [0.68348638, 0.9027701 , 0.33541983, 0.99948256],\n",
       "       [0.17034731, 0.75695908, 0.27652049, 0.5312315 ],\n",
       "       [0.85965692, 0.91959232, 0.20613873, 0.09779683],\n",
       "       [0.28213837, 0.50598691, 0.53053084, 0.09630162],\n",
       "       [0.32607578, 0.4723669 , 0.453192  , 0.10588734],\n",
       "       [0.94838936, 0.89451301, 0.85163782, 0.55219629],\n",
       "       [0.66495539, 0.04656628, 0.11677747, 0.79371778],\n",
       "       [0.57776561, 0.42877174, 0.42582587, 0.24900741],\n",
       "       [0.73861301, 0.48210263, 0.70936644, 0.50397001],\n",
       "       [0.8548108 , 0.49396462, 0.73530997, 0.80809201]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depedencies,\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# SKOPT imports,\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.learning.gaussian_process.kernels import Matern, ConstantKernel, WhiteKernel\n",
    "from skopt import Optimizer\n",
    "from joblib import dump, load\n",
    "\n",
    "# Loading known evaluations,\n",
    "X, y = np.load(\"initial_inputs.npy\"), np.load(\"initial_outputs.npy\")\n",
    "\n",
    "# Inspecting evalutation points,\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67241a45",
   "metadata": {},
   "source": [
    "Despite the sparsity of data points, the domain of the black box function seems to be $[0, 1]^4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "972ed7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22.10828779, -14.60139663, -11.69993246, -16.05376511,\n",
       "       -10.06963343, -15.48708254, -12.68168498, -16.02639977,\n",
       "       -17.04923465, -12.74176599, -27.31639636, -13.52764887,\n",
       "       -16.6791152 , -16.50715856, -17.81799934, -26.56182083,\n",
       "       -12.75832422, -19.44155762, -28.90327367, -13.70274694,\n",
       "       -29.4270914 , -11.56574199, -26.85778644,  -7.96677535,\n",
       "        -6.70208925, -32.62566022, -19.98949793,  -4.02554228,\n",
       "       -13.12278233, -23.1394284 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting black-box outputs,\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f055dda",
   "metadata": {},
   "source": [
    "The output of the black-box function seem to always be negative and of similar magnitude. We want to maximise $f\\mathbf(x)$ so that we can minimise the difference from the expensive baseline. Our data points are too sparse to come up with a conclusion on the smoothness of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a804fb5",
   "metadata": {},
   "source": [
    "### Optimiser Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c339295",
   "metadata": {},
   "source": [
    "From the discription of the black-box function $f(\\mathbf{x})$, we know,\n",
    "\n",
    "- It has many local maxima. \n",
    "- Unlikely to be noisy (problem discription has not mentioned noise).\n",
    "\n",
    "However, we do NOT know,\n",
    "\n",
    "- If $f(\\mathbf{x})$ is very smooth, generally smooth or rough.\n",
    "\n",
    "Again since we do not know the smoothness of $f(\\mathbf{x})$, we opt for the MatÃ©rn 5/2 kernel (with ARD) as it provides a flexible prior that does not enforce excessive smoothness. LCB with a decaying expoitation/exploration trade-off parameter $\\kappa$ is choosen as the acquistion function. Initially, a large value of \n",
    "$\\kappa$ encourages exploration, allowing the optimiser to sample broadly across the input space and identify multiple promising regions corresponding to different local maxima. As $\\kappa$ decays over iterations, the optimisation strategy progressively shifts toward exploitation. Given the multimodal nature of f(x), this design choice intentionally increases the likelihood that the optimiser converges to and exploits a high-quality local maximum rather than continuing extensive global exploration in pursuit of the global optimum. This approach reflects a deliberate trade-off between exploration and exploitation under a limited evaluation budget, prioritising reliable convergence to a strong local solution.\n",
    "\n",
    "Our initial kappa, is set to $\\kappa_0=5.0$ (high amount of exploration) and decays exponentially in accordance to,\n",
    "\n",
    "$$\n",
    "\\kappa(n) = \\kappa_0 e^{-\\frac{n}{\\tau}}\n",
    "$$\n",
    "\n",
    "where $n$ is the number of interactions and $\\tau$ is the reciprocal of our decay rate. We set $\\tau = 3.75$ such that $\\kappa(n) > 1$ (exploitation favoured) when $n > 6$ (we have a total of 12 evaluations). For completion, the elements of our kernel $\\mathbf{K}$ are given by,\n",
    "\n",
    "$$\n",
    "K(\\mathbf{x}_i, \\mathbf{x}_j)\n",
    "=\n",
    "\\sigma^2\n",
    "\\frac{2^{1-\\nu}}{\\Gamma(\\nu)}\n",
    "\\left(\n",
    "\\sqrt{2\\nu}\\, r_{ij}\n",
    "\\right)^{\\nu}\n",
    "K_{\\nu}\n",
    "\\left(\n",
    "\\sqrt{2\\nu}\\, r_{ij}\n",
    "\\right),\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{ij}\n",
    "=\n",
    "\\sqrt{\n",
    "\\frac{(x_{i1} - x_{j1})^2}{\\ell_1^2}\n",
    "+\n",
    "\\frac{(x_{i2} - x_{j2})^2}{\\ell_2^2}\n",
    "+\n",
    "\\frac{(x_{i3} - x_{j3})^2}{\\ell_3^2}\n",
    "+\n",
    "\\frac{(x_{i4} - x_{j4})^2}{\\ell_4^2}\n",
    "}.\n",
    "$$\n",
    "\n",
    "where we have set the lengthscales as $\\ell_1 = \\ell_2 = \\ell_3 = \\ell_4 = 0.1$ and used $\\nu = 5/2$ as well as $\\sigma = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734ac53",
   "metadata": {},
   "source": [
    "### Optimiser Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9574c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point Query: [0.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"INITALISING THE OPTIMISATION MODEL.\"\"\"\n",
    "\n",
    "# Inputting the given evaluations provided by the problem,\n",
    "X_supplied = X.tolist()\n",
    "y_supplied = y.tolist()\n",
    "\n",
    "# Inital kappa value,\n",
    "initial_kappa = 5\n",
    "\n",
    "\"\"\"OPTIMISER SETTINGS.\"\"\"\n",
    "\n",
    "# We define the domain of the black-box function (or the range of the parameter values we want to consider),\n",
    "space = [Real(0, 1, name=\"x1\"),\n",
    "         Real(0, 1, name=\"x2\"),\n",
    "         Real(0, 1, name=\"x3\"),\n",
    "         Real(0, 1, name=\"x4\")\n",
    "         ]\n",
    "\n",
    "# Creating the kernel for the GPR,\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=(0.1, 0.1, 0.1, 0.1),\n",
    "    length_scale_bounds=(1e-2, 1.0),\n",
    "    nu = 5/2)\n",
    "\n",
    "# GPR settings,\n",
    "gpr = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=10\n",
    ")\n",
    "\n",
    "# Creating optimisier,\n",
    "opt = Optimizer(\n",
    "    dimensions=space,\n",
    "    base_estimator=gpr,\n",
    "    acq_func=\"LCB\",\n",
    "    acq_func_kwargs={\"kappa\": initial_kappa},\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "\"\"\"CREATING INTIAL OPTIMISER STATE.\"\"\"\n",
    "\n",
    "# Supplying given points to optimiser,\n",
    "opt.tell(X_supplied, (-np.array(y_supplied)).tolist()) # <-- We flip the values since we are trying to maximise the black-box function.\n",
    "\n",
    "# Asking for the next point to evaluate the black-box function,\n",
    "point_query = opt.ask()\n",
    "\n",
    "# Saving optimiser state (zero-th iteration),\n",
    "dump(opt, \"bayes_opt_state_iter0.joblib\")\n",
    "\n",
    "# Printing point query,\n",
    "print(f\"Point Query: {point_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c3c51",
   "metadata": {},
   "source": [
    "### Next Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63811f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_decay(init_kappa, decay_param, iter_num):\n",
    "    \"\"\"Outputs a value of kappa given the current interaction number (current query number).\"\"\"\n",
    "    return init_kappa*np.exp(-(iter_num/decay_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_query = 1\n",
    "\n",
    "# Input the new evaluation,\n",
    "X_new = [[]]\n",
    "y_new = []\n",
    "\n",
    "# Loading the previous state of the optimiser,\n",
    "opt = load(f\"bayes_opt_state_iter{current_query - 1}.joblib\")\n",
    "\n",
    "# Updating kappa,\n",
    "new_kappa = kappa_decay(init_kappa=initial_kappa, decay_param=3.75, iter_num=current_query)\n",
    "opt.acq_func_kwargs[\"kappa\"] = new_kappa\n",
    "\n",
    "# Supplying the new query to the optimiser,\n",
    "opt.tell(X_new, (-np.array(y_new)).tolist()) # <-- We flip the values since we are trying to maximise the black-box function.\n",
    "\n",
    "# Asking for the next point to evaluate the black-box function,\n",
    "point_query = opt.ask()\n",
    "\n",
    "# Saving optimiser state,\n",
    "dump(opt, f\"bayes_opt_state_iter{current_query}.joblib\")\n",
    "\n",
    "# Printing point query,\n",
    "print(f\"Point Query {current_query + 1}: {point_query}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
